{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1700a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5cfbcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3a6435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_1 = 'dataset/bad/45.jpg'\n",
    "img_path_2 = 'dataset/bad/50.jpg'\n",
    "img_path_3 = 'dataset/good/45.jpg'\n",
    "img_path_4 = 'dataset/good/5.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a87936d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(img_path_1)\n",
    "img2 = cv2.imread(img_path_2)\n",
    "img3 = cv2.imread(img_path_3)\n",
    "img4 = cv2.imread(img_path_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6228300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_r1 = cv2.resize(img1, (128,128))\n",
    "img_r2 = cv2.resize(img2, (128,128))\n",
    "img_r3 = cv2.resize(img3, (128,128))\n",
    "img_r4 = cv2.resize(img4, (128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b77c4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_test_img = np.array([np.array(img_r1), np.array(img_r2), np.array(img_r3), np.array(img_r4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f90d29cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 128, 128, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "807f34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(np_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93e61403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6668a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['bad', 'good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "384fef6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dd2a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_i = y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "900172a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f974cf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bf75c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_i_r = y_pred_i.reshape((4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec208d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_op = [classes[y] for y in y_pred_i_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0458fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad', 'bad', 'good', 'good']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a15a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('myenv\\cv\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c8787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting program and cleaning up\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3,640) #3->width\n",
    "cam.set(4,400) #4->height\n",
    "while(True):\n",
    "    success,frame = cam.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) #cascade classifier works on grayscale images\n",
    "    faces = face_cascade.detectMultiScale(gray,1.3,5) #scaleFactor=1.3, minNeighbors=5 \n",
    "    # detectMultiScale returns the tuple of coordinates of the detected face, if no face is detected it returns an empty tuple\n",
    "    for (x,y,w,h) in faces:\n",
    "        frame1 = cv2.resize(frame, (128,128))\n",
    "        np_frame = np.array(frame1)\n",
    "        np_frame1 = np_frame.reshape((1,np_frame.shape[0], np_frame.shape[1],np_frame.shape[2]))\n",
    "#         cv2.putText(frame,str(np_frame1.shape),(x+w,y),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),2)\n",
    "        y_pred = model.predict(np_frame1)\n",
    "        y_pred_i = y_pred.astype(int)\n",
    "        y_x = y_pred_i.shape[0]\n",
    "        y_pred_i_r = y_pred_i.reshape((y_x,))\n",
    "        output = [classes[y] for y in y_pred_i_r]\n",
    "#         cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.putText(frame,output[0],(280,300),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow('Camera', frame)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if(k==27):\n",
    "        break\n",
    "print('Exiting program and cleaning up')\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c1655e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv]",
   "language": "python",
   "name": "conda-env-cv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
